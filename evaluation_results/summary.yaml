fasttext:
  m1:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: test training
      train_data_description: 10% sample of german wikipedia, single txt, one sentence
        per line, lowercased, removed punctuation
      train_data_size: 685M
      train_data_md5_hash: 9683602ee186844125ed90eff1fb2dff
      training_epochs: 10
      training_vector_size: 200
      training_duration (minutes): 37.0
      model_data_size: 2.4G
    score:
      synonyms: 0.03999999910593033
      homonyms: 0.09000000357627869
      antonyms: -0.03999999910593033
  m2:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: test training
      train_data_description: 10% sample of german wikipedia, single txt, one sentence
        per line, lowercased, removed punctuation
      train_data_size: 685M
      train_data_md5_hash: 9683602ee186844125ed90eff1fb2dff
      training_epochs: 100
      training_vector_size: 200
      training_duration (minutes): 371.9
      model_data_size: 2.4G
    score:
      synonyms: 0.05999999865889549
      homonyms: 0.10000000149011612
      antonyms: -0.05999999865889549
word2vec:
  m1:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: word2vec test model
      train_data_description: 10% sample of german wikipedia, single txt, one sentence
        per line, lowercased, removed punctuation
      train_data_size: 685M
      train_data_md5_hash: 9683602ee186844125ed90eff1fb2dff
      training_vector_size: 200
      training_epochs: 10
      window: 5
      min_count: 5
      training_duration (minutes): 43.6
      model_data_size: 19M
    score:
      synonyms: 0.09
      homonyms: 0.05
      antonyms: -0.08
  m2:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: word2vec test model
      train_data_description: 10% sample of german wikipedia, single txt, one sentence
        per line, lowercased, removed punctuation
      train_data_size: 685M
      train_data_md5_hash: 9683602ee186844125ed90eff1fb2dff
      training_vector_size: 200
      training_epochs: 100
      window: 5
      min_count: 5
      training_duration (minutes): 215.8
      model_data_size: 19M
    score:
      synonyms: 0.08
      homonyms: 0.04
      antonyms: -0.07
  m3:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 10% AMC model
      train_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
        sampled, lowercased, punctuation removed, cleaned from lines not having enough
        text'
      train_data_size: 5.4G
      train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
      training_vector_size: 200
      training_epochs: 10
      window: 5
      min_count: 5
      training_duration (minutes): 165.3
      model_data_size: 56M
    score:
      synonyms: 0.13
      homonyms: 0.12
      antonyms: -0.09
glove:
  m1:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: glove test model
      train_data_description: 10% sample of german wikipedia, single txt, one article
        per line, lowercased, removed punctuation
      train_data_size: 679M
      train_data_md5_hash: 09bd7f10c1437cc41e32fdda80ba4a34
      verbose: '2'
      memory: '4'
      vocab_min_count: '5'
      vector_size: '200'
      max_iter: '10'
      window_size: '15'
      binary: '2'
      num_threads: '14'
      x_max: '10'
      training_duration (minutes): 47.45
      model_data_size: 16G
    score:
      synonyms: 0.06
      homonyms: 0.04
      antonyms: -0.1
  m2:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: glove test model
      train_data_description: 10% sample of german wikipedia, single txt, one article
        per line, lowercased, removed punctuation
      train_data_size: 679M
      train_data_md5_hash: 09bd7f10c1437cc41e32fdda80ba4a34
      verbose: '2'
      memory: '4'
      vocab_min_count: '5'
      vector_size: '200'
      max_iter: '100'
      window_size: '15'
      binary: '2'
      num_threads: '14'
      x_max: '10'
      training_duration (minutes): 391.06
      model_data_size: 16G
    score:
      synonyms: 0.07
      homonyms: 0.01
      antonyms: -0.12
